{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Vegetation Indices (VIs) Calculation Using Harmonized Landsat and Sentinel-2 (HLS) Imagery\n",
    "\n",
    "Using the Harmonized Landsat and Sentinel-2 (HLS) surface reflectance dataset<sup> [1]</sup>, the team is developing canopy chlorophyll and Gross Primary Production (GPP) equations based on Vegetation Indices (VIs). The team was working with extracted HLS data and VIs, and is now applying the GPP equations to the HLS imagery. The data for this project is currently available under the NASA Center for Climate Simulation (NCCS) ADAPT system, primarily located in the following directories:\n",
    "\n",
    "```bash\n",
    "L30: /att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30\n",
    "S30: /att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30/S30\n",
    "YEARS: 2015-2019\n",
    "```\n",
    "\n",
    "This notebook is an enhancement of existing MATLAB scripts in order to calculate VIs from extracted spectral values. The idea is to apply the calculated indices to the images and make spatial/geo-referenced maps of the VIs. The team would like to scale the indices 0-1 and apply the canopy chlorophyll and GPP equations to the VI images (scaled and not scaled). This notebook is arquitected to apply to L30 and S30 imagery, and it will require slight modifications in order to apply to additional datasets. For additional information on the bands available via the HLS dataset, feel free to visit <https://lpdaac.usgs.gov/data/get-started-data/collection-overview/missions/harmonized-landsat-sentinel-2-hls-overview/>.\n",
    "\n",
    "**Author:** Jordan A. Caraballo-Vega - NASA GSFC, <jordan.a.caraballo-vega@nasa.gov> <br/>\n",
    "**Release Date:** 07/23/2021 <br/>\n",
    "**Version:** 2021.10 <br/>\n",
    "\n",
    "## 1. Usage and installation requirements\n",
    "\n",
    "## 1.1 Creating a conda environment (One time only)\n",
    "\n",
    "In order to run this notebook you will need a conda environment with all dependencies installed. ADAPT provides a built-in environment from the JupyterHub interface that is only missing a couple of packages that can be installed on the fly. In order to get started quickly, follow the next steps:\n",
    "\n",
    "1. Login to adaptlogin.nccs.nasa.gov\n",
    "2. Load the Anaconda module\n",
    "\n",
    "```bash\n",
    "module load anaconda3\n",
    "```\n",
    "\n",
    "3. Install new environment or clone the existing environment\n",
    "\n",
    "```bash\n",
    "conda config --add channels conda-forge\n",
    "conda config --set channel_priority strict\n",
    "conda create -y -n hls-vis-gpp rioxarray cupy cudatoolkit=11.2 dask-cuda cudnn cutensor nccl ipykernel ipywidgets matplotlib geopandas iteration_utilities\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "conda create --name hls-vis --clone /att/nobackup/jacaraba/.conda/envs/hls-vis\n",
    "```\n",
    "\n",
    "Now you are ready to move on to JupyterHub.\n",
    "\n",
    "## 1.2 Login to ADAPT JupyterHub\n",
    "\n",
    "To leverage NCCS ADAPT resources, you will need to login to ADAPT JupyterHub. The steps are outlined below.\n",
    "\n",
    "1. Login to the NCCS JupyterHub <https://www-proxy-dev.nccs.nasa.gov/jupyterhub-prism/>.\n",
    "2. Open this notebook via the file/upload method.\n",
    "3. Select kernel, in this case \"hls-vis\".\n",
    "4. Start working on your notebook.\n",
    "\n",
    "## 2. Define global variables for the HLS dataset\n",
    "\n",
    "\n",
    "## 2.1 Import Python Libraries\n",
    "\n",
    "In this section we include all Python libraries required to execute the code below. There are no external code dependencies besides the packages installed under section 1.1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as xrx\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import ipywidgets as widgets\n",
    "import multiprocessing as mp\n",
    "\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of processors:  40\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Define Global Variables\n",
    "\n",
    "In this section we define global variables utilized across the entire notebook. The variables together with their description are listed below. In this section the user will define the directory where the data resides.\n",
    "\n",
    "- **DATA_PATH (string):** define the directory where data resides, year directories should be located under this path followed by .hdf files. An example of this would be: /att/nobackup/user/L30, where /att/nobackup/user/L30/yyyy/imagery.hdf exists.\n",
    "- **OUTPUT_PATH (string):** define the directory where output data will be stored, year directories will be auto-generated under this path followed by .hdf files. An example of this would be: /att/nobackup/user/output/L30, where /att/nobackup/user/output/L30/yyyy/imagery_vis.tif will be created.\n",
    "\n",
    "In this section the user will need to define the DATA_PATH and OUTPUT_PATH variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# User should modify DATA_PATH and OUTPUT_PATH accordingly\n",
    "#DATA_PATH = '/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30'\n",
    "#OUTPUT_PATH = '/att/gpfsfs/briskfs01/ppl/jacaraba/testing-gpp-gpu-01-mask/L30'\n",
    "DATA_PATH = '/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30/S30'\n",
    "OUTPUT_PATH = '/att/gpfsfs/briskfs01/ppl/jacaraba/testing-gpp-gpu-01-mask/S30'\n",
    "NUM_PROCESSES = 10\n",
    "NODATA_VAL = -9999.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "- **MASK_OPTIONS (dict):** The HLS dataset provides a set of masks that can be retrieved from the QA band of the imagery. The variable MASK_OPTIONS lets the user define which masks are available for selection. This variable will then be used in the checkbox menu to determine which masks will be calculated and applied.\n",
    "- **VIS_OPTIONS_S30 (dict):** A list of VIs is available through the provided MATLAB script. Different sets of VIs can be calculated based on the selected satellite. This variable defines the available VIs from the Sentinel imagery.\n",
    "- **VIS_OPTIONS_L30 (dict):** Similar to VIS_OPTIONS_S30, this varible defines the available VIs from the Landsat imagery.\n",
    "\n",
    "No input from the user is required in this section, unless bands in the imagery change, or new VIs are introduced in this project for calculation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# DO NOT MODIFY THIS SECTION UNLESS YOU HAVE MORE MASKS OR INDICES TO INCLUDE.\n",
    "# IPYWIDGETS REQUIRES A DICTIONARY THAT INCLUDES BOTH THE NAME AND LABEL.\n",
    "\n",
    "# MASK_OPTIONS: DICTIONARY WITH AVAILABLE MASKS\n",
    "MASK_OPTIONS = {\n",
    "    'ADJCLOUD':    'ADJCLOUD',\n",
    "    'AQ':          'AQ',\n",
    "    'CIRRUS':      'CIRRUS',\n",
    "    'CLOUD':       'CLOUD',\n",
    "    'CLOUDSHADOW': 'CLOUDSHADOW',\n",
    "    'SNOW':        'SNOW',\n",
    "    'WATER':       'WATER'\n",
    "}\n",
    "\n",
    "# MASK_BITS: DICTIONARY WITH MASK BITS RANGE\n",
    "MASK_BITS = {\n",
    "    'ADJCLOUD':    [5, 6],\n",
    "    'AQ':          [0, 2],\n",
    "    'CIRRUS':      [7, 8],\n",
    "    'CLOUD':       [6, 7],\n",
    "    'CLOUDSHADOW': [4, 5],\n",
    "    'SNOW':        [3, 4],\n",
    "    'WATER':       [2, 3]\n",
    "}\n",
    "\n",
    "# BANDS: DICTIONARY WITH BANDS FROM IMAGERY FOR GPU TRANSFER\n",
    "BANDS = {\n",
    "    'L30': [\n",
    "        'band01', 'band11', 'QA', 'band02', 'band03', 'band04', 'band05', 'band06', 'band07', 'band09', 'band10'\n",
    "    ],\n",
    "    'S30': [\n",
    "        'B01', 'B09', 'B10', 'B11', 'B12', 'QA', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A'\n",
    "    ],\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# DO NOT MODIFY THIS SECTION UNLESS YOU HAVE MORE MASKS OR INDICES TO INCLUDE.\n",
    "# IPYWIDGETS REQUIRES A DICTIONARY THAT INCLUDES BOTH THE NAME AND LABEL.\n",
    "\n",
    "# VIS_OPTIONS_S30: DICTIONARY WITH AVAILABLE VIS FOR S30\n",
    "VIS_OPTIONS_S30 = {\n",
    "    'SR':          'SR',\n",
    "    'NDVI':        'NDVI',\n",
    "    'SAVI':        'SAVI',\n",
    "    'MSAVI':       'MSAVI',\n",
    "    'OSAVI':       'OSAVI',\n",
    "    'EVI':         'EVI',\n",
    "    'TVI':         'TVI',\n",
    "    'MTVI1':       'MTVI1',\n",
    "    'MTVI2':       'MTVI2',\n",
    "    'CVI':         'CVI',\n",
    "    'GNDVI':       'GNDVI',\n",
    "    'CIG':         'CIG',\n",
    "    'NGRDI':       'NGRDI',\n",
    "    'GLI':         'GLI',\n",
    "    'VARI':        'VARI',\n",
    "    'FCVI':        'FCVI',\n",
    "    'FCVI_VIS':    'FCVI_VIS',\n",
    "    'NDREI':       'NDREI',\n",
    "    'CIRE':        'CIRE',\n",
    "    'MTCI':        'MTCI',\n",
    "    'MCARI':       'MCARI',\n",
    "    'TCARI':       'TCARI',\n",
    "    'TCI':         'TCI',\n",
    "    'TCARI_OSAVI': 'TCARI_OSAVI',\n",
    "    'MCARI_MTVI2': 'MCARI_MTVI2',\n",
    "    'TGI':         'TGI',\n",
    "    'NDVI705':     'NDVI705',\n",
    "    'NDVI740':     'NDVI740',\n",
    "    'CI705':       'CI705',\n",
    "    'CI740':       'CI740',\n",
    "    'CCCI':        'CCCI',\n",
    "    'RE1RE2':      'RE1RE2',\n",
    "    'REIP3':       'REIP3',\n",
    "}\n",
    "\n",
    "# VIS_OPTIONS_L30: DICTIONARY WITH AVAILABLE VIS FOR L30\n",
    "VIS_OPTIONS_L30 = {\n",
    "    'SR':          'SR',\n",
    "    'NDVI':        'NDVI',\n",
    "    'SAVI':        'SAVI',\n",
    "    'MSAVI':       'MSAVI',\n",
    "    'OSAVI':       'OSAVI',\n",
    "    'EVI':         'EVI',\n",
    "    'TVI':         'TVI',\n",
    "    'MTVI1':       'MTVI1',\n",
    "    'MTVI2':       'MTVI2',\n",
    "    'CVI':         'CVI',\n",
    "    'GNDVI':       'GNDVI',\n",
    "    'CIG':         'CIG',\n",
    "    'NGRDI':       'NGRDI',\n",
    "    'GLI':         'GLI',\n",
    "    'VARI':        'VARI',\n",
    "    'FCVI':        'FCVI',\n",
    "    'FCVI_VIS':    'FCVI_VIS',\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Define variables to extract VIs from the HLS imagery\n",
    "\n",
    "## 3.1 Widget Functions\n",
    "\n",
    "In this section we define widget functions to assist in the execution of this notebook. These functions take care of the visual implementations of elements that will then be used to finalize Mask and VIs calculations. No input from the user is required in this section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def checkbox_menu(data: dict) -> list:\n",
    "    \"\"\"\n",
    "    Define dynamic widgets for checkbox menu.\n",
    "    Input:\n",
    "        data (dict): dictionary with key and label to initiate checkbox menu\n",
    "    Return: list of selected objects\n",
    "    \"\"\"\n",
    "    names = list()\n",
    "    checkbox_objects = list()\n",
    "    for key in data:\n",
    "        if key == 'AQ': # AQ mask is [1,2,3]\n",
    "            checkbox_objects.append(widgets.Checkbox(value=False, description=key))\n",
    "        else:\n",
    "            checkbox_objects.append(widgets.Checkbox(value=True, description=key))\n",
    "        names.append(key)\n",
    "\n",
    "    # generate dictionary of all arguments in the checkbox menu\n",
    "    arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "\n",
    "    # divide the options in 4 columns, and generate horizontal grid\n",
    "    chunk = int(round(len(checkbox_objects)/3))\n",
    "    ui = widgets.HBox(\n",
    "        [\n",
    "            widgets.VBox(checkbox_objects[i:i+chunk]) for i in range(0, len(checkbox_objects), chunk)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # dynamically allocate values to variable\n",
    "    selected_data = []\n",
    "    def select_data(**kwargs):\n",
    "        selected_data.clear()\n",
    "        for key in kwargs:\n",
    "            if kwargs[key] is True:\n",
    "                selected_data.append(key)\n",
    "        print(selected_data)\n",
    "\n",
    "    out = widgets.interactive_output(select_data, arg_dict)\n",
    "    display(ui)\n",
    "    return selected_data\n",
    "\n",
    "def get_years(data_path: str, year_options: dict = {}) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve dataset available years.\n",
    "    Input:\n",
    "        data_path (str): string with directory where data resides.\n",
    "    Return: dict of available years\n",
    "    \"\"\"\n",
    "    for y in glob(f'{DATA_PATH}/*'):\n",
    "        year = y.split('/')[-1]\n",
    "        year_options[year] = year\n",
    "    return sorted(year_options)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Specify data directory, masks and VIs\n",
    "\n",
    "This notebook allows the user to select between Landsat (L30) and Sentinel-2 (S30) imagery in order to calculate the respective Masks. In this section the user will define the years in question. In addition, the user will select the desired Masks and VIs for calculation.\n",
    "\n",
    "Select between the 3 available checkbox menus for year, masks, and VIs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "SATELLITE = DATA_PATH.split('/')[-1]  # selecting between L30 and S30 based on the last directory of DATA_PATH, no user intervention\n",
    "YEAR_OPTIONS = get_years(DATA_PATH)  # retrieving dataset available years, no user intervention\n",
    "\n",
    "print(f\"Selecting satellite {SATELLITE} and DATA_PATH {DATA_PATH}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selecting satellite S30 and DATA_PATH /att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30/S30\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **YEARS (list string):** define the years that will be processed by this script\n",
    "- **MASKS (list string):** define the masks that will be processed by this script\n",
    "- **VIS (list string):** define the VIS that will be calculated by this script"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# years checkbox menu\n",
    "print(\"Selected Years:\")\n",
    "YEARS = checkbox_menu(YEAR_OPTIONS)\n",
    "\n",
    "# mask checkbox menu\n",
    "print(\"Selected Masks:\")\n",
    "MASKS = checkbox_menu(MASK_OPTIONS)\n",
    "\n",
    "# vis checkbox menu\n",
    "print(f\"Selected VIs for {SATELLITE}:\")\n",
    "VIS = checkbox_menu(VIS_OPTIONS_L30) if SATELLITE == 'L30' else checkbox_menu(VIS_OPTIONS_S30)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selected Years:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='2015'), Checkbox(value=True, description='2016…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd91128edfe4c5bac55cf35e4920831",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selected Masks:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='ADJCLOUD'), Checkbox(value=False, description=…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10b2a1fa0ea41f2920bbd9b6adbe103",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selected VIs for S30:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='SR'), Checkbox(value=True, description='NDVI')…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff76631448fb4d18bc38488a98e1b986",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# print a small summary\n",
    "print(f\"Calculating {len(YEARS)} years, {len(MASKS)} masks, and {len(VIS)} VIs.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating 5 years, 6 masks, and 33 VIs.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Start Mask and VIs Calculations\n",
    "\n",
    "In this section, data files are retrieved and indices are calculated. Make sure to specify the variables in the previous section to allow for a seamless calculation.\n",
    "\n",
    "## 4.1 Get all imagery files\n",
    "\n",
    "In this section we mine through the DATA_PATH to retrive all filenames that will be processed. No input from the user is required in this section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_filenames(data_path: str, years_var: list = ['ALL'], f_ext: str = '.hdf'):\n",
    "    \"\"\"\n",
    "    Retrieve filenames to calculate indices from.\n",
    "    Input:\n",
    "        data_path (str): string with directory where data resides.\n",
    "        years_var (str list): list of years to work with.\n",
    "        f_ext (str): imagery filename extensions.\n",
    "    Return: list of filenames to process\n",
    "    \"\"\"\n",
    "    filenames = list()\n",
    "    if 'ALL' in years_var:  # iterate over all years under the main data path\n",
    "        filenames = glob(f'{data_path}/**/*{f_ext}', recursive=True) + filenames\n",
    "    else: # iterate over the years specified by the user\n",
    "        for y in years_var:\n",
    "            filenames = glob(f'{data_path}/{y}/*{f_ext}', recursive=True) + filenames\n",
    "    assert len(filenames) > 0, f\"No files were found in {data_path}.\"\n",
    "    return filenames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "filenames = get_filenames(data_path=DATA_PATH, years_var=YEARS)\n",
    "print(f\"Processing {len(filenames)} files...\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing 341 files...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 Define function to decode QA mask band\n",
    "\n",
    "Here we need to decode the QA Mask Band. Examples of how to do it are outlined below. No input from the user is required in this section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def get_binary(z: int, width: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve binary representation.\n",
    "    Input:\n",
    "        z (int): string with value to decode\n",
    "        width (int): int identity (HLS is 8 bits)\n",
    "    Return: binary representation for a single value in str format\n",
    "    \"\"\"\n",
    "    if z < 0:\n",
    "        return '0' * 8\n",
    "    else:\n",
    "        return np.binary_repr(z, width=width)\n",
    "    \n",
    "def get_mask(z: str, mid: str, width: int = 8, start_bit: int = 0, end_bit: int = 1) -> int:\n",
    "    \"\"\"\n",
    "    Retrieve mask from binary representation.\n",
    "    Input:\n",
    "        z (str): string with binary representation\n",
    "        width (int): int identity (HLS is 8 bits)\n",
    "        start_bit (int): position of bit in string (starts with 0)\n",
    "        end_bit (int): position of bit in string (starts with 1)\n",
    "    Return: return pixel mask value\n",
    "    \"\"\"\n",
    "    if z == '0' * width:\n",
    "        return 0\n",
    "    else:\n",
    "        if mid == 'AQ': # bin2dec(code(1:2))\n",
    "            return int(z[start_bit:end_bit],2)\n",
    "        else: # 1 - str2num(code(7))\n",
    "            return 1 - int(z[start_bit:end_bit])   \n",
    "\n",
    "# vectorize get_binary and get_mask functions\n",
    "v_get_binary = np.vectorize(get_binary, doc='Vectorized `get_binary_repr`')\n",
    "v_get_mask = np.vectorize(get_mask, doc='Vectorized `get_mask`')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 Define function to apply QA masks\n",
    "\n",
    "Here we apply the QA Mask. Examples of how to do it are outlined below. No input from the user is required in this section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def calculate_mask(qa, mask_id, mask_bits, width=8):\n",
    "    start_bit, end_bit = mask_bits[mask_id][0], mask_bits[mask_id][1]\n",
    "    return {\n",
    "        mask_id: v_get_mask(qa, mask_id, width=width, start_bit=start_bit, end_bit=end_bit)\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.4 Define function to apply S30 VIs\n",
    "\n",
    "Here we calculate S30 VIs. Examples of how to do it are outlined below. No input from the user is required in this section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def apply_vis_s30(ds, VIS_list: list = ['FCVI_VIS']):\n",
    "    \"\"\"\n",
    "    Calculate S30 VIs.\n",
    "    S30 Bands - B01, B09, B10, B11, B12, QA, B02, B03, B04, B05, B06, B07, B08, B8A\n",
    "    Input:\n",
    "        ds (xarray): array with dataset and all bands\n",
    "        VIS_list (list): list of selected VIs to apply\n",
    "    Return: xarray with VIs applied\n",
    "    \"\"\"\n",
    "    with np.errstate(all='ignore'):\n",
    "\n",
    "        if 'SR' in VIS_list:\n",
    "            # b8a_s30_s./b04_s30_s\n",
    "            ds['SR'] = ds['B8A'] / ds['B04']\n",
    "\n",
    "        if 'NDVI' in VIS_list:\n",
    "            # (b8a_s30_s-b04_s30_s)./(b8a_s30_s+b04_s30_s)\n",
    "            ds['NDVI'] = (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'])\n",
    "\n",
    "        if 'SAVI' in VIS_list:\n",
    "            # (1+0.5).*(b8a_s30_s-b04_s30_s)./((b8a_s30_s+b04_s30_s+0.5))\n",
    "            ds['SAVI'] = (1 + 0.5) * (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'] + 0.5)\n",
    "\n",
    "        if 'MSAVI' in VIS_list:\n",
    "            # 0.5.*(2 * b8a_s30_s + 1 - sqrt( (2 * b8a_s30_s + 1).^2-8.*(b8a_s30_s-b04_s30_s) ) )\n",
    "            ds['MSAVI'] = 0.5 * (2 * ds['B8A'] + 1 - np.sqrt( (2 * ds['B8A'] + 1)**2e-8 * (ds['B8A'] - ds['B04'])))\n",
    "\n",
    "        if 'OSAVI' in VIS_list:\n",
    "            # (1+0.16).*(b8a_s30_s-b04_s30_s)./(b8a_s30_s+b04_s30_s+0.16)\n",
    "            ds['OSAVI'] = (1 + 0.16) * (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'] + 0.16)\n",
    "\n",
    "        if 'EVI' in VIS_list:\n",
    "            # 2.5.*(b8a_s30_s-b04_s30_s)./(b8a_s30_s+6*b04_s30_s-7.5*b02_s30_s+1)\n",
    "            ds['EVI'] = 2.5 * (ds['B8A'] - ds['B04']) / (ds['B8A'] + 6 * ds['B04'] - 7.5 * ds['B02'] + 1)\n",
    "\n",
    "        if 'TVI' in VIS_list:\n",
    "            # 0.5.*(120.*(b8a_s30_s-b03_s30_s)-200.*(b04_s30_s-b03_s30_s))\n",
    "            ds['TVI'] = 0.5 * (120 * (ds['B8A'] - ds['B03']) - 200 * (ds['B04'] - ds['B03']))\n",
    "\n",
    "        if 'MTVI1' in VIS_list:\n",
    "            # 1.2*(1.2*(b8a_s30_s-b03_s30_s)-2.5*(b04_s30_s-b03_s30_s))\n",
    "            ds['MTVI1'] = 1.2 * (1.2 * (ds['B8A'] - ds['B03']) - 2.5 * (ds['B04'] - ds['B03']))\n",
    "\n",
    "        if 'MTVI2' in VIS_list:\n",
    "            # 1.5*((1.2*(b8a_s30_s-b03_s30_s)-2.5.*(b04_s30_s-b03_s30_s))./sqrt((2*b8a_s30_s+1).^2-(6.*b8a_s30_s-5*sqrt(b04_s30_s))-0.5))\n",
    "            ds['MTVI2'] = 1.5 * ((1.2 * (ds['B8A'] - ds['B03']) - 2.5 * (ds['B04'] - ds['B03'])) / np.sqrt((2*ds['B8A']+1)**2 - (6 * ds['B8A'] - 5 * np.sqrt(ds['B04'])) - 0.5))\n",
    "\n",
    "        if 'CVI' in VIS_list:\n",
    "            # ((b8a_s30_s).*(b04_s30_s))./((b03_s30_s).^2)\n",
    "            ds['CVI'] = ((ds['B8A']) * (ds['B04'])) / ((ds['B03'])**2)\n",
    "\n",
    "        if 'GNDVI' in VIS_list:\n",
    "            # (b8a_s30_s-b03_s30_s)./(b8a_s30_s+b03_s30_s)\n",
    "            ds['GNDVI'] = (ds['B8A'] - ds['B03']) / (ds['B8A'] + ds['B03'])\n",
    "\n",
    "        if 'CIG' in VIS_list:\n",
    "            # (b8a_s30_s./b04_s30_s)-1\n",
    "            ds['CIG'] = (ds['B8A'] / ds['B04']) - 1.0\n",
    "\n",
    "        if 'NGRDI' in VIS_list:\n",
    "            # (b03_s30_s-b04_s30_s)./(b03_s30_s+b04_s30_s)\n",
    "            ds['NGRDI'] = (ds['B03'] - ds['B04']) / (ds['B03'] + ds['B04'])\n",
    "\n",
    "        if 'GLI' in VIS_list:\n",
    "            # (2*b03_s30_s-b04_s30_s-b02_s30_s)./(2*b03_s30_s+b04_s30_s+b02_s30_s)\n",
    "            ds['GLI'] = (2 * ds['B03'] - ds['B04'] - ds['B02']) / (2 * ds['B03'] + ds['B04'] + ds['B02'])\n",
    "\n",
    "        if 'VARI' in VIS_list:\n",
    "            # (b03_s30_s-b04_s30_s)./(b03_s30_s+b04_s30_s-b02_s30_s)\n",
    "            ds['VARI'] = (ds['B03'] - ds['B04']) / (ds['B03'] + ds['B04'] - ds['B02'])\n",
    "\n",
    "        if 'FCVI' in VIS_list:\n",
    "            # (b8a_s30_s-(b02_s30_s+b03_s30_s+b04_s30_s)./3)\n",
    "            ds['FCVI'] = (ds['B8A'] - (ds['B02'] + ds['B03'] + ds['B04']) / 3.0)\n",
    "\n",
    "        if 'FCVI_VIS' in VIS_list:\n",
    "            # (b8a_s30_s-(b02_s30_s+b03_s30_s+b04_s30_s)./3)./((b02_s30_s+b03_s30_s+b04_s30_s)./3)\n",
    "            ds['FCVI_VIS'] = (ds['B8A'] - (ds['B02'] + ds['B03'] + ds['B04']) / 3.0) / ((ds['B02'] + ds['B03'] + ds['B04']) / 3.0)\n",
    "\n",
    "        if 'NDREI' in VIS_list:\n",
    "            # (b8a_s30_s-b06_s30_s)./(b8a_s30_s+b06_s30_s);\n",
    "            ds['NDREI'] = (ds['B8A'] - ds['B06']) / (ds['B8A'] + ds['B06'])\n",
    "\n",
    "        if 'CIRE' in VIS_list:\n",
    "            # (b8a_s30_s./b06_s30_s)-1, note: same formula as CI740\n",
    "            ds['CIRE'] = (ds['B8A'] / ds['B06']) - 1.0\n",
    "\n",
    "        if 'MTCI' in VIS_list:\n",
    "            # (b06_s30_s-b05_s30_s)./(b05_s30_s-b04_s30_s);\n",
    "            ds['MTCI'] = (ds['B06'] - ds['B05']) / (ds['B05'] - ds['B04'])\n",
    "\n",
    "        if 'MCARI' in VIS_list:\n",
    "            # ((b05_s30_s-b04_s30_s)-0.2.*(b05_s30_s-b03_s30_s))./((b06_s30_s)./(b04_s30_s));\n",
    "            ds['MCARI'] = ((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B06'] / ds['B04'])\n",
    "\n",
    "        if 'TCARI' in VIS_list:\n",
    "            # 3*(((b05_s30_s-b04_s30_s)-0.2*(b05_s30_s-b03_s30_s))./(b05_s30_s./b04_s30_s));\n",
    "            ds['TCARI'] = 3 * (((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B05'] / ds['B04']))\n",
    "\n",
    "        if 'TCI' in VIS_list:\n",
    "            # 1.2*(b05_s30_s-b03_s30_s)-1.5.*(b04_s30_s-b03_s30_s).*sqrt(b05_s30_s./b04_s30_s);\n",
    "            ds['TCI'] = 1.2 * (ds['B05'] - ds['B03']) - 1.5 * (ds['B04'] - ds['B03']) * np.sqrt(ds['B05'] / ds['B04'])\n",
    "\n",
    "        if 'TCARI_OSAVI' in VIS_list:\n",
    "            # TCARI_S30./OSAVI_S30; dependent on TCARI and OSAVI\n",
    "            ds['TCARI'] = 3 * (((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B05'] / ds['B04']))\n",
    "            ds['OSAVI'] = (1 + 0.16) * (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'] + 0.16)\n",
    "            ds['TCARI_OSAVI'] = ds['TCARI'] / ds['OSAVI']\n",
    "\n",
    "        if 'MCARI_MTVI2' in VIS_list:\n",
    "            # MCARI_S30./MTVI2_S30; dependent on MCARI and MTVI2\n",
    "            ds['MCARI'] = ((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B06'] / ds['B04'])\n",
    "            ds['MTVI2'] = 1.5 * ((1.2 * (ds['B8A'] - ds['B03']) - 2.5 * (ds['B04'] - ds['B03'])) / np.sqrt((2*ds['B8A']+1)**2 - (6 * ds['B8A'] - 5 * np.sqrt(ds['B04'])) - 0.5))\n",
    "            ds['MCARI_MTVI2'] = ds['MCARI'] / ds['MTVI2']\n",
    "\n",
    "        if 'TGI' in VIS_list:\n",
    "            # ((b04_s30_s-(b02_s30_s).*(b04_s30_s-b03_s30_s))-(b04_s30_s-(b03_s30_s).*(b04_s30_s-b02_s30_s))).*(-0.5);\n",
    "            ds['TGI'] = ((ds['B04'] - (ds['B02']) * (ds['B04'] - ds['B03'])) - (ds['B04'] - (ds['B03']) * (ds['B04'] - ds['B02']))) * (-0.5)\n",
    "\n",
    "        if 'NDVI705' in VIS_list:\n",
    "            # (b8a_s30_s-b05_s30_s)./(b8a_s30_s+b05_s30_s);\n",
    "            ds['NDVI705'] = (ds['B8A'] - ds['B05']) / (ds['B8A'] + ds['B05'])\n",
    "\n",
    "        if 'NDVI740' in VIS_list:\n",
    "            # (b8a_s30_s-b06_s30_s)./(b8a_s30_s+b06_s30_s);\n",
    "            ds['NDVI740'] = (ds['B8A'] - ds['B06']) / (ds['B8A'] + ds['B06'])\n",
    "\n",
    "        if 'CI705' in VIS_list:\n",
    "            # (b8a_s30_s./b05_s30_s)-1\n",
    "            ds['CI705'] = (ds['B8A'] / ds['B05']) - 1.0\n",
    "\n",
    "        if 'CI740' in VIS_list:\n",
    "            # (b8a_s30_s./b06_s30_s)-1\n",
    "            ds['CI740'] = (ds['B8A'] / ds['B06']) - 1.0\n",
    "\n",
    "        if 'CCCI' in VIS_list:\n",
    "            # ((b8a_s30_s-b06_s30_s)./(b8a_s30_s+b06_s30_s))./((b8a_s30_s-b04_s30_s)./(b8a_s30_s+b04_s30_s))\n",
    "            ds['CCCI'] = ((ds['B8A'] - ds['B06']) / (ds['B8A'] + ds['B06'])) / ((ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04']))\n",
    "\n",
    "        if 'RE1RE2' in VIS_list:\n",
    "            # (b06_s30_s./b05_s30_s)-1;\n",
    "            ds['RE1RE2'] = (ds['B06'] / ds['B05']) - 1.0\n",
    "\n",
    "        if 'REIP3' in VIS_list:\n",
    "            # 705+35.*(((((b04_s30_s+b8a_s30_s)./2)-b05_s30_s))./(b06_s30_s-b05_s30_s));\n",
    "            ds['REIP3'] = 705 + 35 * (((((ds['B04'] + ds['B8A']) / 2) - ds['B05'])) / (ds['B06'] - ds['B05']))\n",
    "\n",
    "    return ds.fillna(0)  # fill nan values with 0s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.5 Define function to apply L30 VIs\n",
    "\n",
    "Here we calculate L30 VIs. Examples of how to do it are outlined below. No input from the user is required in this section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def apply_vis_l30(ds, VIS_list: list = ['SR']):\n",
    "    \"\"\"\n",
    "    Calculate L30 VIs.\n",
    "    L30 Bands - band01, band11, QA, band02, band03, band04, band05, band06, band07, band09, band10\n",
    "    Input:\n",
    "        ds (xarray): array with dataset and all bands\n",
    "        VIS_list (list): list of selected VIs to apply\n",
    "    Return: xarray with VIs applied\n",
    "    \"\"\"\n",
    "    with np.errstate(all='ignore'):\n",
    "\n",
    "        if 'SR' in VIS_list:\n",
    "            # SR_L30=b05_l30_s./b04_l30_s;\n",
    "            ds['SR'] = ds['band05'] / ds['band04']\n",
    "\n",
    "        if 'NDVI' in VIS_list:\n",
    "            # NDVI_L30=(b05_l30_s-b04_l30_s)./(b05_l30_s+b04_l30_s);\n",
    "            ds['NDVI'] = (ds['band05'] - ds['band04']) / (ds['band05'] + ds['band04'])\n",
    "\n",
    "        if 'SAVI' in VIS_list:\n",
    "            # SAVI_L30=(1+0.5).*(b05_l30_s-b04_l30_s)./((b05_l30_s+b04_l30_s+0.5)); \n",
    "            ds['SAVI'] = (1 + 0.5) * (ds['band05'] - ds['band04']) / ((ds['band05'] + ds['band04'] + 0.5))\n",
    "\n",
    "        if 'MSAVI' in VIS_list:\n",
    "            # MSAVI_L30=0.5.*(2.*b05_l30_s+1-sqrt((2.*b05_l30_s+1).^2-8.*(b05_l30_s-b04_l30_s)));\n",
    "            ds['MSAVI'] = 0.5 * (2 * ds['band05'] + 1 - np.sqrt((2 * ds['band05'] + 1)**2e-8 * (ds['band05'] - ds['band04'])))\n",
    "\n",
    "        if 'OSAVI' in VIS_list:\n",
    "            # OSAVI_L30=(1+0.16).*(b05_l30_s-b04_l30_s)./(b05_l30_s+b04_l30_s+0.16);\n",
    "            ds['OSAVI'] = (1 + 0.16) * (ds['band05'] - ds['band04']) / (ds['band05'] + ds['band04'] + 0.16)\n",
    "\n",
    "        if 'EVI' in VIS_list:\n",
    "            # EVI_L30=2.5.*(b05_l30_s-b04_l30_s)./(b05_l30_s+6.*(b04_l30_s)-7.5.*(b02_l30_s)+1);\n",
    "            ds['EVI'] = 2.5 * (ds['band05'] - ds['band04']) / (ds['band05'] + 6 * (ds['band04']) - 7.5 * (ds['band02']) + 1)\n",
    "\n",
    "        if 'TVI' in VIS_list:\n",
    "            # TVI_L30=0.5.*(120.*(b05_l30_s-b03_l30_s)-200.*(b04_l30_s-b03_l30_s));\n",
    "            ds['TVI'] = 0.5 * (120 * (ds['band05'] - ds['band03']) - 200 * (ds['band04'] - ds['band03']))\n",
    "\n",
    "        if 'MTVI1' in VIS_list:\n",
    "            # MTVI1_L30=1.2*(1.2*(b05_l30_s-b03_l30_s)-2.5*(b04_l30_s-b03_l30_s));\n",
    "            ds['MTVI1'] = 1.2 * (1.2 * (ds['band05'] - ds['band03']) - 2.5 * (ds['band04'] - ds['band03']))\n",
    "\n",
    "        # is the exponent after the negative? or is that a substraction?\n",
    "        if 'MTVI2' in VIS_list:\n",
    "            # MTVI2_L30=1.5*((1.2*(b05_l30_s-b03_l30_s)-2.5.*(b04_l30_s-b03_l30_s))./sqrt((2*b05_l30_s+1).^2-(6.*b05_l30_s-5*sqrt(b04_l30_s))-0.5));\n",
    "            ds['MTVI2'] = 1.5 * ((1.2 * (ds['band05'] - ds['band03']) - 2.5 * (ds['band04'] - ds['band03'])) / np.sqrt((2 * ds['band05'] + 1)**2 - (6 * ds['band05']- 5 * np.sqrt(ds['band04'])) - 0.5))\n",
    "\n",
    "        if 'CVI' in VIS_list:\n",
    "            # CVI_L30=(b05_l30_s).*((b04_l30_s)./((b03_l30_s).^2));\n",
    "            ds['CVI'] = (ds['band05']) * ((ds['band04']) / ((ds['band03'])**2))\n",
    "\n",
    "        if 'GNDVI' in VIS_list:\n",
    "            # GNDVI_L30=(b05_l30_s-b03_l30_s)./(b05_l30_s+b03_l30_s);\n",
    "            ds['GNDVI'] = (ds['band05'] - ds['band03']) / (ds['band05'] + ds['band03'])\n",
    "\n",
    "        if 'CIG' in VIS_list:\n",
    "            # CIG_L30=((b05_l30_s)./(b04_l30_s))-1;\n",
    "            ds['CIG'] = ((ds['band05']) / (ds['band04'])) - 1.0\n",
    "\n",
    "        if 'NGRDI' in VIS_list:\n",
    "            # NGRDI_L30=(b03_l30_s-b04_l30_s)./(b03_l30_s+b04_l30_s);\n",
    "            ds['NGRDI'] = (ds['band03'] - ds['band04']) / (ds['band03'] + ds['band04'])\n",
    "\n",
    "        if 'GLI' in VIS_list:\n",
    "            # GLI_L30=(2.*(b03_l30_s)-(b04_l30_s+b02_l30_s))./(2.*(b03_l30_s)+b04_l30_s+b02_l30_s);\n",
    "            ds['GLI'] = (2 * (ds['band03']) - (ds['band04'] + ds['band02'])) / (2 * (ds['band03']) + ds['band04'] + ds['band02'])\n",
    "\n",
    "        if 'VARI' in VIS_list:\n",
    "            # VARI_L30=(b03_l30_s-b04_l30_s)./(b03_l30_s+b04_l30_s-b02_l30_s);\n",
    "            ds['VARI'] = (ds['band03'] - ds['band04']) / (ds['band03'] + ds['band04'] - ds['band02'])\n",
    "\n",
    "        if 'FCVI' in VIS_list:\n",
    "            # FCVI_L30=(b05_l30_s-(b02_l30_s+b03_l30_s+b04_l30_s)./3);\n",
    "            ds['FCVI'] = (ds['band05'] - (ds['band02'] + ds['band03'] + ds['band04']) / 3.0)\n",
    "\n",
    "        if 'FCVI_VIS' in VIS_list:\n",
    "            # FCVI_VIS_L30=(b05_l30_s-(b02_l30_s+b03_l30_s+b04_l30_s)./3)./((b02_l30_s+b03_l30_s+b04_l30_s)./3);\n",
    "            ds['FCVI_VIS'] = (ds['band05'] - (ds['band02'] + ds['band03'] + ds['band04']) / 3) / ((ds['band02'] + ds['band03'] + ds['band04']) / 3)\n",
    "\n",
    "    return ds.fillna(0)  # fill nan values with 0s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.6 Iterate over each file and output GeoTIF files\n",
    "\n",
    "Here we define the function to iterate over each file and process both mask and VIs. Each file is taking around ~3 minutes to process, saving into disk takes some time. \n",
    "\n",
    "The process has been slightly parallelized, but can be improved even more. Two additional things can be parallelized here: process many files at the same time or parallelize functions to calculate indices."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def _xarray_to_cupy_(ds, band: str):\n",
    "    return xr.DataArray(cp.asarray(ds[band]), dims=[\"band\", \"y\", \"x\"])\n",
    "\n",
    "def _xarray_to_numpy_(ds, band: str):\n",
    "    return xr.DataArray(cp.asnumpy(ds[band]), dims=[\"band\", \"y\", \"x\"])\n",
    "\n",
    "def process_filename(f: str, vis: list, bands: dict, masks: list, output_path: str):\n",
    "    \"\"\"\n",
    "    Process each HDF HLS file.\n",
    "    Input:\n",
    "        f (str): filename\n",
    "        vis (list): list of selected VIs to apply\n",
    "        masks (list): list of selected masks to apply\n",
    "        output_path (str): directory to store files\n",
    "    Return: xarray with VIs applied\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # create output directory if not present\n",
    "        output_dir = os.path.join(output_path, f.split('/')[-2])\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # define output filename\n",
    "        output_file = os.path.join(output_dir, f.split('/')[-1][:-4] + '.gpp.vis.tif')\n",
    "\n",
    "        if not os.path.exists(output_file):\n",
    "\n",
    "            # open the dataset from the hdf imagery\n",
    "            hls_ds = xrx.open_rasterio(f)\n",
    "\n",
    "            # decode qa_mask for the generation of external masks\n",
    "            qa_mask = v_get_binary(hls_ds['QA'].values)\n",
    "\n",
    "            # reorder bands since rasterio reads them in numbered order, move to GPU\n",
    "            hls_ds_tmp, hls_ds = hls_ds, hls_ds.drop(bands[SATELLITE])\n",
    "\n",
    "            for b in sorted(bands[SATELLITE]):\n",
    "                hls_ds[b] = _xarray_to_cupy_(ds=hls_ds_tmp, band=b)\n",
    "            hls_ds = (hls_ds.drop('QA') / 10000.0).astype(cp.float32)\n",
    "\n",
    "            # parallelize mask calculation process\n",
    "            pool = mp.Pool(processes=NUM_PROCESSES)\n",
    "            mask_processes = [pool.apply_async(calculate_mask, args=(qa_mask, x, MASK_BITS, 8)) for x in masks]\n",
    "\n",
    "            # retrieve and apply required masks\n",
    "            final_mask = cp.ones((hls_ds['y'].shape[0], hls_ds['x'].shape[0]), dtype=cp.int8)            \n",
    "            for p in mask_processes:\n",
    "                final_mask = final_mask * cp.asarray(list(p.get().values())[0])\n",
    "            final_mask = hls_ds[bands[SATELLITE][0]].copy(data=final_mask).astype(bool)\n",
    "\n",
    "            # calculate indices\n",
    "            hls_ds = apply_vis_l30(hls_ds, vis) if SATELLITE == 'L30' else apply_vis_s30(hls_ds, vis)            \n",
    "            hls_ds = xr.where(final_mask, hls_ds, NODATA_VAL).astype('float32')\n",
    "\n",
    "            # assign nodata metadata\n",
    "            final_bands = a = [x for x in bands[SATELLITE] + vis if x != 'QA']\n",
    "            for bb in final_bands:\n",
    "                hls_ds[bb] = hls_ds[bb].rio.write_nodata(NODATA_VAL)\n",
    "\n",
    "            # need to drop some indices before output to local disk?\n",
    "            # dropind =  ['band11', 'band04', 'band05', 'band06', 'band07', 'band09', 'band10']\n",
    "            # hls_ds = hls_ds.drop(dropind)\n",
    "\n",
    "            hls_ds.rio.write_crs(\"EPSG:32618\", inplace=True)\n",
    "            hls_ds.isel(band=0).rio.to_raster(output_file, compress='LZW')\n",
    "            return output_file\n",
    "\n",
    "        else:\n",
    "            print(f\"{output_file} exists, skipping.\")\n",
    "            return None\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{f} does not have a QA band available, skipping the calculation of VIs. Check module installation.')\n",
    "        return None\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "# Serial approach\n",
    "# 5 files\n",
    "# CPU times: user 2min 18s, sys: 31.8 s, total: 2min 50s\n",
    "# Wall time: 4min 33s\n",
    "for f in filenames:\n",
    "    print(f, datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    process_filename(f, vis=VIS, bands=BANDS, masks=MASKS, output_path=OUTPUT_PATH)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30/S30/2019/HLS.S30.T18SUJ.2019279.v1.4.hdf 15:01:44\n",
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30/S30/2019/HLS.S30.T18SUJ.2019171.v1.4.hdf 15:02:47\n",
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30/S30/2019/HLS.S30.T18SUJ.2019199.v1.4.hdf 15:04:00\n",
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30/S30/2019/HLS.S30.T18SUJ.2019156.v1.4.hdf 15:05:01\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Visual Validation (Optional)\n",
    "\n",
    "In this section we visualize some bands to confirm the output of the notebook include the original dataset, calculated masks, and calculated VIs. The user may specify any files here for further analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ORIGINAL_FILENAME = '/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30/2015/HLS.L30.T18SUJ.2015149.v1.4.hdf'\n",
    "# VIS_FILENAME = '/att/gpfsfs/briskfs01/ppl/jacaraba/testing-gpp/L30/2015/HLS.L30.T18SUJ.2015149.v1.4.gpp.vis.tif'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# visualize original filename\n",
    "# original_ds = xrx.open_rasterio(ORIGINAL_FILENAME)\n",
    "# band01, band02, band03 = original_ds['band01'].values, original_ds['band02'].values, original_ds['band03'].values\n",
    "# original_vis = np.concatenate((band01, band02, band03), axis=0)\n",
    "# original_vis = np.clip(original_vis, 0, 10000)\n",
    "# original_vis = np.moveaxis(original_vis, 0, -1) / 10000.0\n",
    "# plt.imshow(original_vis)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# visualize vis filename\n",
    "# vis_ds = xrx.open_rasterio(VIS_FILENAME)\n",
    "# vis_ds.attrs['long_name']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# vis_CIG_band = vis_ds[10, :, :].values\n",
    "# vis_CIG_band = np.moveaxis(vis_CIG_band, 0, -1)\n",
    "# plt.imshow(vis_CIG_band)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from matplotlib import colors\n",
    "# cmap = colors.ListedColormap(['r','b'])\n",
    "# az = np.squeeze(hls_ds['SAVI'])\n",
    "# plt.imshow(az)#, cmap=cmap)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}