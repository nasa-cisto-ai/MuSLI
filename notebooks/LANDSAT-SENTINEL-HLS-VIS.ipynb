{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vegetation Indices (VIs) Calculation Using Harmonized Landsat and Sentinel-2 (HLS) Imagery\n",
    "\n",
    "Using the Harmonized Landsat and Sentinel-2 (HLS) surface reflectance dataset<sup> [1]</sup>, the team is developing canopy chlorophyll and Gross Primary Production (GPP) equations based on Vegetation Indices (VIs). The team was working with extracted HLS data and VIs, and is now applying the GPP equations to the HLS imagery. The data for this project is currently available under the NASA Center for Climate Simulation (NCCS) ADAPT system, primarily located in the following directories:\n",
    "\n",
    "```bash\n",
    "L30: /att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30\n",
    "S30: /att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.S30\n",
    "YEARS: 2015-2019\n",
    "```\n",
    "\n",
    "This notebook is an enhancement of existing MATLAB scripts in order to calculate VIs from extracted spectral values. The idea is to apply the calculated indices to the images and make spatial/geo-referenced maps of the VIs. The team would like to scale the indices 0-1 and apply the canopy chlorophyll and GPP equations to the VI images (scaled and not scaled). This notebook is arquitected to apply to L30 and S30 imagery, and it will require slight modifications in order to apply to additional datasets. For additional information on the bands available via the HLS dataset, feel free to visit <https://lpdaac.usgs.gov/data/get-started-data/collection-overview/missions/harmonized-landsat-sentinel-2-hls-overview/>.\n",
    "\n",
    "**Author:** Jordan A. Caraballo-Vega - NASA GSFC, <jordan.a.caraballo-vega@nasa.gov> <br/>\n",
    "**Release Date:** 07/01/2021 <br/>\n",
    "**Version:** 1.0.1 <br/>\n",
    "\n",
    "TODO:\n",
    "\n",
    "- MASK pixels if outside of the image or NaN, else %in image – I was extracting the spectra ( I think that I am not doing this)\n",
    "- Remove original bands from the resulting geotif?\n",
    "\n",
    "## 1. Usage and installation requirements\n",
    "\n",
    "## 1.1 Creating a conda environment (One time only)\n",
    "\n",
    "In order to run this notebook you will need a conda environment with all dependencies installed. ADAPT provides a built-in environment from the JupyterHub interface that is only missing a couple of packages that can be installed on the fly. In order to get started quickly, follow the next steps:\n",
    "\n",
    "1. Login to adaptlogin.nccs.nasa.gov\n",
    "2. Load the Anaconda module and initialize the earthml environment\n",
    "\n",
    "```bash\n",
    "module load anaconda3\n",
    "conda activate earthml\n",
    "```\n",
    "3. Install missing dependency\n",
    "\n",
    "```bash\n",
    "pip install --user rioxarray\n",
    "```\n",
    "Now you are ready to move on to JupyterHub.\n",
    "\n",
    "## 1.2 Login to ADAPT JupyterHub\n",
    "\n",
    "To leverage NCCS ADAPT resources, you will need to login to ADAPT JupyterHub. The steps are outlined below.\n",
    "\n",
    "1. Login to the NCCS JupyterHub <https://www-proxy-dev.nccs.nasa.gov/jupyterhub-adapt/>.\n",
    "2. Open this notebook via the file/upload method.\n",
    "3. Select kernel, in this case \"earthml\".\n",
    "4. Start working on your notebook.\n",
    "\n",
    "## 2. Define global variables for the HLS dataset\n",
    "\n",
    "\n",
    "## 2.1 Import Python Libraries\n",
    "\n",
    "In this section we include all Python libraries required to execute the code below. There are no external code dependencies besides the packages installed under section 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import rioxarray as xrx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import ipywidgets as widgets\n",
    "import multiprocessing as mp\n",
    "\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define Global Variables\n",
    "\n",
    "In this section we define global variables utilized across the entire notebook. The variables together with their description are listed below.\n",
    "\n",
    "- **MASK_OPTIONS (dict):** The HLS dataset provides a set of masks that can be retrieved from the QA band of the imagery. The variable MASK_OPTIONS lets the user define which masks are available for selection. This variable will then be used in the checkbox menu to determine which masks will be calculated and applied.\n",
    "- **VIS_OPTIONS_S30 (dict):** A list of VIs is available through the provided MATLAB script. Different sets of VIs can be calculated based on the selected satellite. This variable defines the available VIs from the Sentinel imagery.\n",
    "- **VIS_OPTIONS_L30 (dict):** Similar to VIS_OPTIONS_S30, this varible defines the available VIs from the Landsat imagery.\n",
    "\n",
    "No input from the user is required in this section, unless bands in the imagery change, or new VIs are introduced in this project for calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS SECTION UNLESS YOU HAVE MORE MASKS OR INDICES TO INCLUDE.\n",
    "# IPYWIDGETS REQUIRES A DICTIONARY THAT INCLUDES BOTH THE NAME AND LABEL.\n",
    "\n",
    "# MASK_OPTIONS: DICTIONARY WITH AVAILABLE MASKS\n",
    "MASK_OPTIONS = {\n",
    "    'ADJCLOUD':    'ADJCLOUD',\n",
    "    'AQ':          'AQ',\n",
    "    'CIRRUS':      'CIRRUS',\n",
    "    'CLOUD':       'CLOUD',\n",
    "    'CLOUDSHADOW': 'CLOUDSHADOW',\n",
    "    'SNOW':        'SNOW',\n",
    "    'WATER':       'WATER'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS SECTION UNLESS YOU HAVE MORE MASKS OR INDICES TO INCLUDE.\n",
    "# IPYWIDGETS REQUIRES A DICTIONARY THAT INCLUDES BOTH THE NAME AND LABEL.\n",
    "\n",
    "# VIS_OPTIONS_S30: DICTIONARY WITH AVAILABLE VIS FOR S30\n",
    "VIS_OPTIONS_S30 = {\n",
    "    'CI705':       'CI705',\n",
    "    'CI740':       'CI740',\n",
    "    'CCCI':        'CCCI',\n",
    "    'CIG':         'CIG',\n",
    "    'CIRE':        'CIRE',\n",
    "    'CVI':         'CVI',\n",
    "    'EVI':         'EVI',\n",
    "    'FCVI':        'FCVI',\n",
    "    'FCVI_VIS':    'FCVI_VIS',\n",
    "    'GLI':         'GLI',\n",
    "    'GNDVI':       'GNDVI',\n",
    "    'MCARI':       'MCARI',\n",
    "    'MCARI_MTVI2': 'MCARI_MTVI2',\n",
    "    'MSAVI':       'MSAVI',\n",
    "    'MTCI':        'MTCI',\n",
    "    'MTVI1':       'MTVI1',\n",
    "    'MTVI2':       'MTVI2',\n",
    "    'NDREI':       'NDREI',\n",
    "    'NDVI':        'NDVI',\n",
    "    'NDVI705':     'NDVI705',\n",
    "    'NDVI740':     'NDVI740',\n",
    "    'NGRDI':       'NGRDI',\n",
    "    'OSAVI':       'OSAVI',\n",
    "    'RE1RE2':      'RE1RE2',\n",
    "    'REIP3':       'REIP3',\n",
    "    'SAVI':        'SAVI',\n",
    "    'SR':          'SR',\n",
    "    'TCARI':       'TCARI',\n",
    "    'TCARI_OSAVI': 'TCARI_OSAVI',\n",
    "    'TCI':         'TCI',\n",
    "    'TGI':         'TGI',\n",
    "    'TVI':         'TVI',\n",
    "    'VARI':        'VARI'\n",
    "}\n",
    "\n",
    "# VIS_OPTIONS_L30: DICTIONARY WITH AVAILABLE VIS FOR L30\n",
    "VIS_OPTIONS_L30 = {\n",
    "    'CIG':         'CIG',\n",
    "    'CVI':         'CVI',\n",
    "    'EVI':         'EVI',\n",
    "    'FCVI':        'FCVI',\n",
    "    'FCVI_VIS':    'FCVI_VIS',\n",
    "    'GLI':         'GLI',\n",
    "    'GNDVI':       'GNDVI',\n",
    "    'MSAVI':       'MSAVI',\n",
    "    'MTVI1':       'MTVI1',\n",
    "    'MTVI2':       'MTVI2',\n",
    "    'NDVI':        'NDVI',\n",
    "    'NGRDI':       'NGRDI',\n",
    "    'OSAVI':       'OSAVI',\n",
    "    'SAVI':        'SAVI',\n",
    "    'SR':          'SR',\n",
    "    'TVI':         'TVI',\n",
    "    'VARI':        'VARI'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define variables to extract VIs from the HLS imagery\n",
    "\n",
    "## 3.1 Widget Functions\n",
    "\n",
    "In this section we define widget functions to assist in the execution of this notebook. These functions take care of the visual implementations of elements that will then be used to finalize Mask and VIs calculations. No input from the user is required in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkbox_menu(data: dict) -> list:\n",
    "    \"\"\"\n",
    "    Define dynamic widgets for checkbox menu.\n",
    "    Input:\n",
    "        data (dict): dictionary with key and label to initiate checkbox menu\n",
    "    Return: list of selected objects\n",
    "    \"\"\"\n",
    "    names = list()\n",
    "    checkbox_objects = list()\n",
    "    for key in data:\n",
    "        checkbox_objects.append(widgets.Checkbox(value=True, description=key))\n",
    "        names.append(key)\n",
    "\n",
    "    # generate dictionary of all arguments in the checkbox menu\n",
    "    arg_dict = {names[i]: checkbox for i, checkbox in enumerate(checkbox_objects)}\n",
    "\n",
    "    # divide the options in 4 columns, and generate horizontal grid\n",
    "    chunk = int(round(len(checkbox_objects)/3))\n",
    "    ui = widgets.HBox(\n",
    "        [\n",
    "            widgets.VBox(checkbox_objects[i:i+chunk]) for i in range(0, len(checkbox_objects), chunk)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # dynamically allocate values to variable\n",
    "    selected_data = []\n",
    "    def select_data(**kwargs):\n",
    "        selected_data.clear()\n",
    "        for key in kwargs:\n",
    "            if kwargs[key] is True:\n",
    "                selected_data.append(key)\n",
    "        print(selected_data)\n",
    "\n",
    "    out = widgets.interactive_output(select_data, arg_dict)\n",
    "    display(ui)\n",
    "    return selected_data\n",
    "\n",
    "def get_years(data_path: str, year_options: dict = {}) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve dataset available years.\n",
    "    Input:\n",
    "        data_path (str): string with directory where data resides.\n",
    "    Return: dict of available years\n",
    "    \"\"\"\n",
    "    for y in glob(f'{DATA_PATH}/*'):\n",
    "        year = y.split('/')[-1]\n",
    "        year_options[year] = year\n",
    "    return sorted(year_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Specify data directory, masks and VIs\n",
    "\n",
    "This notebook allows the user to select between Landsat (L30) and Sentinel-2 (S30) imagery in order to calculate the respective Masks. In this section the user will define the directory where the data resides, together with the years in question. In addition, the user will select the desired Masks and VIs for calculation.\n",
    "\n",
    "- **DATA_PATH (string):** define the directory where data resides, year directories should be located under this path followed by .hdf files. An example of this would be: /att/nobackup/user/L30, where /att/nobackup/user/L30/yyyy/imagery.hdf exists.\n",
    "- **OUTPUT_PATH (string):** define the directory where output data will be stored, year directories will be auto-generated under this path followed by .hdf files. An example of this would be: /att/nobackup/user/output/L30, where /att/nobackup/user/output/L30/yyyy/imagery_vis.tif will be created.\n",
    "\n",
    "In this section the user will need to define the DATA_PATH and OUTPUT_PATH variables, and select between the 3 available checkbox menus for year, masks, and VIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting satellite L30 and DATA_PATH /att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30\n"
     ]
    }
   ],
   "source": [
    "# User should modify DATA_PATH and OUTPUT_PATH accordingly\n",
    "DATA_PATH = '/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30'\n",
    "OUTPUT_PATH = '/att/gpfsfs/briskfs01/ppl/jacaraba/testing-gpp-serial-test-01/L30'\n",
    "\n",
    "SATELLITE = DATA_PATH.split('/')[-1]  # selecting between L30 and S30 based on the last directory of DATA_PATH, no user intervention\n",
    "YEAR_OPTIONS = get_years(DATA_PATH)  # retrieving dataset available years, no user intervention\n",
    "\n",
    "print(f\"Selecting satellite {SATELLITE} and DATA_PATH {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **YEARS (list string):** define the years that will be processed by this script\n",
    "- **MASKS (list string):** define the masks that will be processed by this script\n",
    "- **VIS (list string):** define the VIS that will be calculated by this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Years:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810700b6059d4de7879d50174b6b235e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='2015'), Checkbox(value=True, description='2016…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Masks:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d09077c07c4251a7c00b0763354115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='ADJCLOUD'), Checkbox(value=True, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected VIs for L30:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd30b908ddd4fadbcf0ead927c555b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='CIG'), Checkbox(value=True, description='CVI')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# years checkbox menu\n",
    "print(\"Selected Years:\")\n",
    "YEARS = checkbox_menu(YEAR_OPTIONS)\n",
    "\n",
    "# mask checkbox menu\n",
    "print(\"Selected Masks:\")\n",
    "MASKS = checkbox_menu(MASK_OPTIONS)\n",
    "\n",
    "# vis checkbox menu\n",
    "print(f\"Selected VIs for {SATELLITE}:\")\n",
    "VIS = checkbox_menu(VIS_OPTIONS_L30) if SATELLITE == 'L30' else checkbox_menu(VIS_OPTIONS_S30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 5 years, 7 masks, and 17 VIs.\n"
     ]
    }
   ],
   "source": [
    "# print a small summary\n",
    "print(f\"Calculating {len(YEARS)} years, {len(MASKS)} masks, and {len(VIS)} VIs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Mask and VIs Calculations\n",
    "\n",
    "In this section, data files are retrieved and indices are calculated. Make sure to specify the variables in the previous section to allow for a seamless calculation.\n",
    "\n",
    "## 4.1 Get all imagery files\n",
    "\n",
    "In this section we mine through the DATA_PATH to retrive all filenames that will be processed. No input from the user is required in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(data_path: str, years_var: list = ['ALL'], f_ext: str = '.hdf'):\n",
    "    \"\"\"\n",
    "    Retrieve filenames to calculate indices from.\n",
    "    Input:\n",
    "        data_path (str): string with directory where data resides.\n",
    "        years_var (str list): list of years to work with.\n",
    "        f_ext (str): imagery filename extensions.\n",
    "    Return: list of filenames to process\n",
    "    \"\"\"\n",
    "    filenames = list()\n",
    "    if 'ALL' in years_var:  # iterate over all years under the main data path\n",
    "        filenames = glob(f'{data_path}/**/*{f_ext}', recursive=True) + filenames\n",
    "    else: # iterate over the years specified by the user\n",
    "        for y in years_var:\n",
    "            filenames = glob(f'{data_path}/{y}/*{f_ext}', recursive=True) + filenames\n",
    "    assert len(filenames) > 0, f\"No files were found in {data_path}.\"\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 222 files...\n"
     ]
    }
   ],
   "source": [
    "filenames = get_filenames(data_path=DATA_PATH, years_var=YEARS)\n",
    "print(f\"Processing {len(filenames)} files...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Define function to decode QA mask band\n",
    "\n",
    "Here we need to decode the QA Mask Band. Examples of how to do it are outlined below. No input from the user is required in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary(z: int, width: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve binary representation.\n",
    "    Input:\n",
    "        z (int): string with value to decode\n",
    "        width (int): int identity (HLS is 8 bits)\n",
    "    Return: binary representation for a single value in str format\n",
    "    \"\"\"\n",
    "    if z < 0:\n",
    "        return '0' * width\n",
    "    else:\n",
    "        return np.binary_repr(z, width=width)\n",
    "    \n",
    "def get_mask(z: str, width: int = 8, start_bit: int = 0, end_bit: int = 1) -> int:\n",
    "    \"\"\"\n",
    "    Retrieve mask from binary representation.\n",
    "    Input:\n",
    "        z (str): string with binary representation\n",
    "        width (int): int identity (HLS is 8 bits)\n",
    "        start_bit (int): position of bit in string (starts with 0)\n",
    "        end_bit (int): position of bit in string (starts with 1)\n",
    "    Return: return pixel mask value\n",
    "    \"\"\"\n",
    "    if z == '0' * width:\n",
    "        return 0\n",
    "    else: # 1 - str2num(code(7))\n",
    "        return 1 - int(z[start_bit:end_bit])\n",
    "\n",
    "# vectorize get_binary and get_mask functions\n",
    "v_get_binary = np.vectorize(get_binary, doc='Vectorized `get_binary_repr`')\n",
    "v_get_mask = np.vectorize(get_mask, doc='Vectorized `get_mask`')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Define function to apply QA masks\n",
    "\n",
    "Here we apply the QA Mask. Examples of how to do it are outlined below. No input from the user is required in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_masks(ds, qa, masks_list: list = ['CLOUD'], width: int = 8) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve masks from HLS dataset.\n",
    "    Input:\n",
    "        ds (xarray): array with dataset and all bands\n",
    "        qa (xarray): array with QA band values\n",
    "        masks_list (list): list of selected masks to apply\n",
    "        width (int): int identity (HLS is 8 bits)\n",
    "    Return: xarray with masks applied\n",
    "    \"\"\"\n",
    "    mask_ds = dict()  # directory to store calculated masks\n",
    "\n",
    "    if 'ADJCLOUD' in masks_list or 'ALL' in masks_list:\n",
    "        mask_ds['ADJCLOUD'] = v_get_mask(qa, width=width, start_bit=5, end_bit=6)\n",
    "        ds = ds * mask_ds['ADJCLOUD']\n",
    "\n",
    "    if 'AQ' in masks_list or 'ALL' in masks_list:\n",
    "        mask_ds['AQ'] = v_get_mask(qa, width=width, start_bit=0, end_bit=2)\n",
    "        ds = ds * mask_ds['AQ']\n",
    "\n",
    "    if 'CIRRUS' in masks_list or 'ALL' in masks_list:\n",
    "        mask_ds['CIRRUS'] = v_get_mask(qa, width=width, start_bit=7, end_bit=8)\n",
    "        ds = ds * mask_ds['CIRRUS']\n",
    "    \n",
    "    if 'CLOUD' in masks_list or 'ALL' in masks_list:\n",
    "        mask_ds['CLOUD'] = v_get_mask(qa, width=width, start_bit=6, end_bit=7)\n",
    "        ds = ds * mask_ds['CLOUD']\n",
    "    \n",
    "    if 'CLOUDSHADOW' in masks_list or 'ALL' in masks_list:\n",
    "        mask_ds['CLOUDSHADOW'] = v_get_mask(qa, width=width, start_bit=4, end_bit=5)\n",
    "        ds = ds * mask_ds['CLOUDSHADOW']\n",
    "\n",
    "    if 'SNOW' in masks_list or 'ALL' in masks_list:\n",
    "        mask_ds['SNOW'] = v_get_mask(qa, width=width, start_bit=3, end_bit=4)\n",
    "        ds = ds * mask_ds['SNOW']\n",
    "\n",
    "    if 'WATER' in masks_list or 'ALL' in masks_list:\n",
    "        mask_ds['WATER'] = v_get_mask(qa, width=width, start_bit=2, end_bit=3)\n",
    "        ds = ds * mask_ds['WATER']\n",
    "    \n",
    "    return ds, mask_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Define function to apply S30 VIs\n",
    "\n",
    "Here we calculate S30 VIs. Examples of how to do it are outlined below. No input from the user is required in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vis_s30(ds, VIS_list: list = ['FCVI_VIS']):\n",
    "    \"\"\"\n",
    "    Calculate S30 VIs.\n",
    "    S30 Bands - B01, B09, B10, B11, B12, QA, B02, B03, B04, B05, B06, B07, B08, B8A\n",
    "    Input:\n",
    "        ds (xarray): array with dataset and all bands\n",
    "        VIS_list (list): list of selected VIs to apply\n",
    "    Return: xarray with VIs applied\n",
    "    \"\"\"\n",
    "    with np.errstate(all='ignore'):\n",
    "\n",
    "        if 'CI705' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s./b05_s30_s)-1\n",
    "            ds['CI705'] = (ds['B8A'] / ds['B05']) - 1.0\n",
    "\n",
    "        if 'CI740' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s./b06_s30_s)-1\n",
    "            ds['CI740'] = (ds['B8A'] / ds['B06']) - 1.0\n",
    "\n",
    "        if 'CCCI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # ((b8a_s30_s-b06_s30_s)./(b8a_s30_s+b06_s30_s))./((b8a_s30_s-b04_s30_s)./(b8a_s30_s+b04_s30_s))\n",
    "            ds['CCCI'] = ((ds['B8A'] - ds['B06']) / (ds['B8A'] + ds['B06'])) / ((ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04']))\n",
    "\n",
    "        if 'CIG' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s./b04_s30_s)-1\n",
    "            ds['CIG'] = (ds['B8A'] / ds['B04']) - 1.0\n",
    "\n",
    "        if 'CIRE' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s./b06_s30_s)-1, note: same formula as CI740\n",
    "            ds['CIRE'] = (ds['B8A'] / ds['B06']) - 1.0\n",
    "\n",
    "        if 'CVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # ((b8a_s30_s).*(b04_s30_s))./((b03_s30_s).^2)\n",
    "            ds['CVI'] = ((ds['B8A']) * (ds['B04'])) / ((ds['B03'])**2)\n",
    "\n",
    "        if 'EVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 2.5.*(b8a_s30_s-b04_s30_s)./(b8a_s30_s+6*b04_s30_s-7.5*b02_s30_s+1)\n",
    "            ds['EVI'] = 2.5 * (ds['B8A'] - ds['B04']) / (ds['B8A'] + 6 * ds['B04'] - 7.5 * ds['B02'] + 1)\n",
    "\n",
    "        if 'FCVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s-(b02_s30_s+b03_s30_s+b04_s30_s)./3)\n",
    "            ds['FCVI'] = (ds['B8A'] - (ds['B02'] + ds['B03'] + ds['B04']) / 3.0)\n",
    "\n",
    "        if 'FCVI_VIS' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s-(b02_s30_s+b03_s30_s+b04_s30_s)./3)./((b02_s30_s+b03_s30_s+b04_s30_s)./3)\n",
    "            ds['FCVI_VIS'] = (ds['B8A'] - (ds['B02'] + ds['B03'] + ds['B04']) / 3.0) / ((ds['B02'] + ds['B03'] + ds['B04']) / 3.0)\n",
    "\n",
    "        if 'GLI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (2*b03_s30_s-b04_s30_s-b02_s30_s)./(2*b03_s30_s+b04_s30_s+b02_s30_s)\n",
    "            ds['GLI'] = (2 * ds['B03'] - ds['B04'] - ds['B02']) / (2 * ds['B03'] + ds['B04'] + ds['B02'])\n",
    "\n",
    "        if 'GNDVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s-b03_s30_s)./(b8a_s30_s+b03_s30_s)\n",
    "            ds['GNDVI'] = (ds['B8A'] - ds['B03']) / (ds['B8A'] + ds['B03'])\n",
    "\n",
    "        if 'MCARI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # ((b05_s30_s-b04_s30_s)-0.2.*(b05_s30_s-b03_s30_s))./((b06_s30_s)./(b04_s30_s));\n",
    "            ds['MCARI'] = ((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B06'] / ds['B04'])\n",
    "\n",
    "        if 'MCARI_MTVI2' in VIS_list or 'ALL' in VIS_list:\n",
    "            # MCARI_S30./MTVI2_S30; dependent on MCARI and MTVI2\n",
    "            ds['MCARI'] = ((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B06'] / ds['B04'])\n",
    "            ds['MTVI2'] = 1.5 * ((1.2 * (ds['B8A'] - ds['B03']) - 2.5 * (ds['B04'] - ds['B03'])) / np.sqrt((2*ds['B8A']+1)**2 - (6 * ds['B8A'] - 5 * np.sqrt(ds['B04'])) - 0.5))\n",
    "            ds['MCARI_MTVI2'] = ds['MCARI'] / ds['MTVI2']\n",
    "\n",
    "        if 'MSAVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 0.5.*(2 * b8a_s30_s + 1 - sqrt( (2 * b8a_s30_s + 1).^2-8.*(b8a_s30_s-b04_s30_s) ) )\n",
    "            ds['MSAVI'] = 0.5 * (2 * ds['B8A'] + 1 - np.sqrt( (2 * ds['B8A'] + 1)**2e-8 * (ds['B8A'] - ds['B04'])))\n",
    "\n",
    "        if 'MTCI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b06_s30_s-b05_s30_s)./(b05_s30_s-b04_s30_s);\n",
    "            ds['MTCI'] = (ds['B06'] - ds['B05']) / (ds['B05'] - ds['B04'])\n",
    "\n",
    "        if 'MTVI1' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 1.2*(1.2*(b8a_s30_s-b03_s30_s)-2.5*(b04_s30_s-b03_s30_s))\n",
    "            ds['MTVI1'] = 1.2 * (1.2 * (ds['B8A'] - ds['B03']) - 2.5 * (ds['B04'] - ds['B03']))\n",
    "\n",
    "        if 'MTVI2' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 1.5*((1.2*(b8a_s30_s-b03_s30_s)-2.5.*(b04_s30_s-b03_s30_s))./sqrt((2*b8a_s30_s+1).^2-(6.*b8a_s30_s-5*sqrt(b04_s30_s))-0.5))\n",
    "            ds['MTVI2'] = 1.5 * ((1.2 * (ds['B8A'] - ds['B03']) - 2.5 * (ds['B04'] - ds['B03'])) / np.sqrt((2*ds['B8A']+1)**2 - (6 * ds['B8A'] - 5 * np.sqrt(ds['B04'])) - 0.5))\n",
    "\n",
    "        if 'NDREI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s-b06_s30_s)./(b8a_s30_s+b06_s30_s);\n",
    "            ds['NDREI'] = (ds['B8A'] - ds['B06']) / (ds['B8A'] + ds['B06'])\n",
    "\n",
    "        if 'NDVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s-b04_s30_s)./(b8a_s30_s+b04_s30_s)\n",
    "            ds['NDVI'] = (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'])\n",
    "\n",
    "        if 'NDVI705' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s-b05_s30_s)./(b8a_s30_s+b05_s30_s);\n",
    "            ds['NDVI705'] = (ds['B8A'] - ds['B05']) / (ds['B8A'] + ds['B05'])\n",
    "\n",
    "        if 'NDVI740' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b8a_s30_s-b06_s30_s)./(b8a_s30_s+b06_s30_s);\n",
    "            ds['NDVI740'] = (ds['B8A'] - ds['B06']) / (ds['B8A'] + ds['B06'])\n",
    "\n",
    "        if 'NGRDI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b03_s30_s-b04_s30_s)./(b03_s30_s+b04_s30_s)\n",
    "            ds['NGRDI'] = (ds['B03'] - ds['B04']) / (ds['B03'] + ds['B04'])\n",
    "\n",
    "        if 'OSAVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (1+0.16).*(b8a_s30_s-b04_s30_s)./(b8a_s30_s+b04_s30_s+0.16)\n",
    "            ds['OSAVI'] = (1 + 0.16) * (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'] + 0.16)\n",
    "\n",
    "        if 'RE1RE2' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b06_s30_s./b05_s30_s)-1;\n",
    "            ds['RE1RE2'] = (ds['B06'] / ds['B05']) - 1.0\n",
    "\n",
    "        if 'REIP3' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 705+35.*(((((b04_s30_s+b8a_s30_s)./2)-b05_s30_s))./(b06_s30_s-b05_s30_s));\n",
    "            ds['REIP3'] = 705 + 35 * (((((ds['B04'] + ds['B8A']) / 2) - ds['B05'])) / (ds['B06'] - ds['B05']))\n",
    "\n",
    "        if 'SAVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (1+0.5).*(b8a_s30_s-b04_s30_s)./((b8a_s30_s+b04_s30_s+0.5))\n",
    "            ds['SAVI'] = (1 + 0.5) * (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'] + 0.5)\n",
    "\n",
    "        if 'SR' in VIS_list or 'ALL' in VIS_list:\n",
    "            # b8a_s30_s./b04_s30_s\n",
    "            ds['SR'] = ds['B8A'] / ds['B04']\n",
    "\n",
    "        if 'TCARI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 3*(((b05_s30_s-b04_s30_s)-0.2*(b05_s30_s-b03_s30_s))./(b05_s30_s./b04_s30_s));\n",
    "            ds['TCARI'] = 3 * (((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B05'] / ds['B04']))\n",
    "\n",
    "        if 'TCARI_OSAVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # TCARI_S30./OSAVI_S30; dependent on TCARI and OSAVI\n",
    "            ds['TCARI'] = 3 * (((ds['B05'] - ds['B04']) - 0.2 * (ds['B05'] - ds['B03'])) / (ds['B05'] / ds['B04']))\n",
    "            ds['OSAVI'] = (1 + 0.16) * (ds['B8A'] - ds['B04']) / (ds['B8A'] + ds['B04'] + 0.16)\n",
    "            ds['TCARI_OSAVI'] = ds['TCARI'] / ds['OSAVI']\n",
    "\n",
    "        if 'TCI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 1.2*(b05_s30_s-b03_s30_s)-1.5.*(b04_s30_s-b03_s30_s).*sqrt(b05_s30_s./b04_s30_s);\n",
    "            ds['TCI'] = 1.2 * (ds['B05'] - ds['B03']) - 1.5 * (ds['B04'] - ds['B03']) * np.sqrt(ds['B05'] / ds['B04'])\n",
    "\n",
    "        if 'TGI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # ((b04_s30_s-(b02_s30_s).*(b04_s30_s-b03_s30_s))-(b04_s30_s-(b03_s30_s).*(b04_s30_s-b02_s30_s))).*(-0.5);\n",
    "            ds['TGI'] = ((ds['B04'] - (ds['B02']) * (ds['B04'] - ds['B03'])) - (ds['B04'] - (ds['B03']) * (ds['B04'] - ds['B02']))) * (-0.5)\n",
    "\n",
    "        if 'TVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # 0.5.*(120.*(b8a_s30_s-b03_s30_s)-200.*(b04_s30_s-b03_s30_s))\n",
    "            ds['TVI'] = 0.5 * (120 * (ds['B8A'] - ds['B03']) - 200 * (ds['B04'] - ds['B03']))\n",
    "\n",
    "        if 'VARI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # (b03_s30_s-b04_s30_s)./(b03_s30_s+b04_s30_s-b02_s30_s)\n",
    "            ds['VARI'] = (ds['B03'] - ds['B04']) / (ds['B03'] + ds['B04'] - ds['B02'])\n",
    "\n",
    "    return ds.fillna(0).astype('float32')  # fill nan values with 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Define function to apply L30 VIs\n",
    "\n",
    "Here we calculate L30 VIs. Examples of how to do it are outlined below. No input from the user is required in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vis_l30(ds, VIS_list: list = ['SR']):\n",
    "    \"\"\"\n",
    "    Calculate L30 VIs.\n",
    "    L30 Bands - band01, band11, QA, band02, band03, band04, band05, band06, band07, band09, band10\n",
    "    Input:\n",
    "        ds (xarray): array with dataset and all bands\n",
    "        VIS_list (list): list of selected VIs to apply\n",
    "    Return: xarray with VIs applied\n",
    "    \"\"\"\n",
    "    with np.errstate(all='ignore'):\n",
    "\n",
    "        if 'CIG' in VIS_list or 'ALL' in VIS_list:\n",
    "            # CIG_L30=((b05_l30_s)./(b04_l30_s))-1;\n",
    "            ds['CIG'] = ((ds['band05']) / (ds['band04'])) - 1.0\n",
    "\n",
    "        if 'CVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # CVI_L30=(b05_l30_s).*((b04_l30_s)./((b03_l30_s).^2));\n",
    "            ds['CVI'] = (ds['band05']) * ((ds['band04']) / ((ds['band03'])**2))\n",
    "\n",
    "        if 'EVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # EVI_L30=2.5.*(b05_l30_s-b04_l30_s)./(b05_l30_s+6.*(b04_l30_s)-7.5.*(b02_l30_s)+1);\n",
    "            ds['EVI'] = 2.5 * (ds['band05'] - ds['band04']) / (ds['band05'] + 6 * (ds['band04']) - 7.5 * (ds['band02']) + 1)\n",
    "\n",
    "        if 'FCVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # FCVI_L30=(b05_l30_s-(b02_l30_s+b03_l30_s+b04_l30_s)./3);\n",
    "            ds['FCVI'] = (ds['band05'] - (ds['band02'] + ds['band03'] + ds['band04']) / 3.0)\n",
    "\n",
    "        if 'FCVI_VIS' in VIS_list or 'ALL' in VIS_list:\n",
    "            # FCVI_VIS_L30=(b05_l30_s-(b02_l30_s+b03_l30_s+b04_l30_s)./3)./((b02_l30_s+b03_l30_s+b04_l30_s)./3);\n",
    "            ds['FCVI_VIS'] = (ds['band05'] - (ds['band02'] + ds['band03'] + ds['band04']) / 3) / ((ds['band02'] + ds['band03'] + ds['band04']) / 3)\n",
    "\n",
    "        if 'GLI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # GLI_L30=(2.*(b03_l30_s)-(b04_l30_s+b02_l30_s))./(2.*(b03_l30_s)+b04_l30_s+b02_l30_s);\n",
    "            ds['GLI'] = (2 * (ds['band03']) - (ds['band04'] + ds['band02'])) / (2 * (ds['band03']) + ds['band04'] + ds['band02'])\n",
    "\n",
    "        if 'GNDVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # GNDVI_L30=(b05_l30_s-b03_l30_s)./(b05_l30_s+b03_l30_s);\n",
    "            ds['GNDVI'] = (ds['band05'] - ds['band03']) / (ds['band05'] + ds['band03'])\n",
    "\n",
    "        if 'MSAVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # MSAVI_L30=0.5.*(2.*b05_l30_s+1-sqrt((2.*b05_l30_s+1).^2-8.*(b05_l30_s-b04_l30_s)));\n",
    "            ds['MSAVI'] = 0.5 * (2 * ds['band05'] + 1 - np.sqrt((2 * ds['band05'] + 1)**2e-8 * (ds['band05'] - ds['band04'])))\n",
    "\n",
    "        if 'MTVI1' in VIS_list or 'ALL' in VIS_list:\n",
    "            # MTVI1_L30=1.2*(1.2*(b05_l30_s-b03_l30_s)-2.5*(b04_l30_s-b03_l30_s));\n",
    "            ds['MTVI1'] = 1.2 * (1.2 * (ds['band05'] - ds['band03']) - 2.5 * (ds['band04'] - ds['band03']))\n",
    "\n",
    "        # is the exponent after the negative? or is that a substraction?\n",
    "        if 'MTVI2' in VIS_list or 'ALL' in VIS_list:\n",
    "            # MTVI2_L30=1.5*((1.2*(b05_l30_s-b03_l30_s)-2.5.*(b04_l30_s-b03_l30_s))./sqrt((2*b05_l30_s+1).^2-(6.*b05_l30_s-5*sqrt(b04_l30_s))-0.5));\n",
    "            ds['MTVI2'] = 1.5 * ((1.2 * (ds['band05'] - ds['band03']) - 2.5 * (ds['band04'] - ds['band03'])) / np.sqrt((2 * ds['band05'] + 1)**2 - (6 * ds['band05']- 5 * np.sqrt(ds['band04'])) - 0.5))\n",
    "\n",
    "        if 'NDVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # NDVI_L30=(b05_l30_s-b04_l30_s)./(b05_l30_s+b04_l30_s);\n",
    "            ds['NDVI'] = (ds['band05'] - ds['band04']) / (ds['band05'] + ds['band04'])\n",
    "\n",
    "        if 'NGRDI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # NGRDI_L30=(b03_l30_s-b04_l30_s)./(b03_l30_s+b04_l30_s);\n",
    "            ds['NGRDI'] = (ds['band03'] - ds['band04']) / (ds['band03'] + ds['band04'])\n",
    "\n",
    "        if 'OSAVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # OSAVI_L30=(1+0.16).*(b05_l30_s-b04_l30_s)./(b05_l30_s+b04_l30_s+0.16);\n",
    "            ds['OSAVI'] = (1 + 0.16) * (ds['band05'] - ds['band04']) / (ds['band05'] + ds['band04'] + 0.16)\n",
    "\n",
    "        if 'SAVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # SAVI_L30=(1+0.5).*(b05_l30_s-b04_l30_s)./((b05_l30_s+b04_l30_s+0.5)); \n",
    "            ds['SAVI'] = (1 + 0.5) * (ds['band05'] - ds['band04']) / ((ds['band05'] + ds['band04'] + 0.5))\n",
    "\n",
    "        if 'SR' in VIS_list or 'ALL' in VIS_list:\n",
    "            # SR_L30=b05_l30_s./b04_l30_s;\n",
    "            ds['SR'] = ds['band05'] / ds['band04']\n",
    "\n",
    "        if 'TVI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # TVI_L30=0.5.*(120.*(b05_l30_s-b03_l30_s)-200.*(b04_l30_s-b03_l30_s));\n",
    "            ds['TVI'] = 0.5 * (120 * (ds['band05'] - ds['band03']) - 200 * (ds['band04'] - ds['band03']))\n",
    "\n",
    "        if 'VARI' in VIS_list or 'ALL' in VIS_list:\n",
    "            # VARI_L30=(b03_l30_s-b04_l30_s)./(b03_l30_s+b04_l30_s-b02_l30_s);\n",
    "            ds['VARI'] = (ds['band03'] - ds['band04']) / (ds['band03'] + ds['band04'] - ds['band02'])\n",
    "\n",
    "    return ds.fillna(0).astype('float32')  # fill nan values with 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Iterate over each file and output GeoTIF files\n",
    "\n",
    "Here we define the function to iterate over each file and process both mask and VIs. Each file is taking around ~3 minutes to process, saving into disk takes some time. \n",
    "\n",
    "The process has been slightly parallelized, but can be improved even more. Two additional things can be parallelized here: process many files at the same time or parallelize functions to calculate indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(f: str, vis: list, masks: list, output_path: str):\n",
    "    \"\"\"\n",
    "    Process each HDF HLS file.\n",
    "    Input:\n",
    "        f (str): filename\n",
    "        vis (list): list of selected VIs to apply\n",
    "        masks (list): list of selected masks to apply\n",
    "        output_path (str): directory to store files\n",
    "    Return: xarray with VIs applied\n",
    "    \"\"\"\n",
    "    # open the dataset from the hdf imagery\n",
    "    hls_ds = xrx.open_rasterio(f)  # want to leverage additional dask features? chunks={'band': 1, 'x': 4096, 'y': 4096})\n",
    "\n",
    "    try:\n",
    "        \n",
    "        # create output directory if not present\n",
    "        output_dir = os.path.join(OUTPUT_PATH, f.split('/')[-2])\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # define output filename\n",
    "        output_file = os.path.join(output_dir, f.split('/')[-1][:-4] + '.gpp.vis.tif')\n",
    "        \n",
    "        if not os.path.exists(output_file):\n",
    "\n",
    "            # decode qa_mask for the generation of external masks\n",
    "            qa_mask = v_get_binary(hls_ds['QA'].values)\n",
    "\n",
    "            # drop QA band and normalize\n",
    "            hls_ds = (hls_ds.drop('QA') / 10000.0).astype('float32')\n",
    "            \n",
    "            #print(hls_ds)\n",
    "            \n",
    "            # Retrieve and apply required masks\n",
    "            hls_ds, mask_ds = apply_masks(ds=hls_ds, qa=qa_mask, masks_list=MASKS)\n",
    "\n",
    "            # calculate indices\n",
    "            hls_ds = apply_vis_l30(hls_ds, VIS) if SATELLITE == 'L30' else apply_vis_s30(hls_ds, VIS)\n",
    "            \n",
    "            # need to drop some indices before output to local disk?\n",
    "            # dropind =  ['band11', 'band04', 'band05', 'band06', 'band07', 'band09', 'band10']\n",
    "            # hls_ds = hls_ds.drop(dropind)\n",
    "\n",
    "            # output raster to file\n",
    "            hls_ds.isel(band=0).rio.to_raster(output_file, compress='LZW')\n",
    "            \n",
    "            #print(hls_ds)\n",
    "\n",
    "            return output_file\n",
    "        \n",
    "        else:\n",
    "            print(f\"Skipping {output_file} since it has been already processed.\")\n",
    "            return None\n",
    "    \n",
    "    except KeyError:\n",
    "        print(f'{f} does not have a QA band available, skipping the calculation of VIs.')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30/2019/HLS.L30.T18SUJ.2019041.v1.4.hdf\n",
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30/2019/HLS.L30.T18SUJ.2019192.v1.4.hdf\n",
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30/2019/HLS.L30.T18SUJ.2019160.v1.4.hdf\n",
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30/2019/HLS.L30.T18SUJ.2019249.v1.4.hdf\n",
      "/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30/2019/HLS.L30.T18SUJ.2019217.v1.4.hdf\n",
      "CPU times: user 10min 24s, sys: 47.3 s, total: 11min 11s\n",
      "Wall time: 12min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %time\n",
    "# Serial approach\n",
    "for f in filenames[:5]:\n",
    "    print(f)\n",
    "    process_filename(f, vis=VIS, masks=MASKS, output_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# parallel - n number of files based on N processes\n",
    "#jobs = []\n",
    "#for f in filenames:\n",
    "#    p = mp.Process(target=process_filename, args=(f, VIS, MASKS, OUTPUT_PATH))\n",
    "#    jobs.append(p)\n",
    "#    p.start()\n",
    "#    \n",
    "#for j in jobs:\n",
    "#    j.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visual Validation (Optional)\n",
    "\n",
    "In this section we visualize some bands to confirm the output of the notebook include the original dataset, calculated masks, and calculated VIs. The user may specify any files here for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL_FILENAME = '/att/gpfsfs/briskfs01/ppl/pentchev/OPE3_HLS/HLS.GSFC.18SUJ.L30/L30/2015/HLS.L30.T18SUJ.2015149.v1.4.hdf'\n",
    "#VIS_FILENAME = '/att/gpfsfs/briskfs01/ppl/jacaraba/testing-gpp/L30/2015/HLS.L30.T18SUJ.2015149.v1.4.gpp.vis.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize original filename\n",
    "#original_ds = xrx.open_rasterio(ORIGINAL_FILENAME)\n",
    "#band01, band02, band03 = original_ds['band01'].values, original_ds['band02'].values, original_ds['band03'].values\n",
    "#original_vis = np.concatenate((band01, band02, band03), axis=0)\n",
    "#original_vis = np.clip(original_vis, 0, 10000)\n",
    "#original_vis = np.moveaxis(original_vis, 0, -1) / 10000.0\n",
    "#plt.imshow(original_vis)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize vis filename\n",
    "#vis_ds = xrx.open_rasterio(VIS_FILENAME)\n",
    "#vis_ds.attrs['long_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis_CIG_band = vis_ds[10, :, :].values\n",
    "#vis_CIG_band = np.moveaxis(vis_CIG_band, 0, -1)\n",
    "#plt.imshow(vis_CIG_band)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import colors\n",
    "# cmap = colors.ListedColormap(['r','b'])\n",
    "# az = np.squeeze(hls_ds['SAVI'])\n",
    "# plt.imshow(az)#, cmap=cmap)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hls-vis]",
   "language": "python",
   "name": "conda-env-.conda-hls-vis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
